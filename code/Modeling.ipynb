{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc5f76b2-5029-4f53-ab49-1c639e61b867",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "In this workbook I will build, tune, and evaluate various classification models with the goal of creating a model that given a political post from a user of social media platforms, such as Reddit, can accurately identify whether the poster is Democrat or Republican. \n",
    "\n",
    "My main evaluation metric will be accuracy however, I will examine false positives and negatives as well as sensitivity and recall scores to ensure the model is flexible to other needs should they arise over the course of the campaign. \n",
    "\n",
    "Overview of Modeling Process:\n",
    "1. Load clean data from previous workbook\n",
    "2. Identify Baseline Metrics of Null Model\n",
    "3. Build & Tune Various Classification Models\n",
    "4. Evaluate Model Metrics (Accuracy, Sensitivity, Precision)\n",
    "5. Conclusion & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bb79551-88b8-4a44-ac39-f9ed47c42b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier, StackingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26509768-c83d-4e7c-8934-b56a2b075a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r demdata\n",
    "%store -r repdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b81739f-4d17-4167-a1d4-c8b6ddb0a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join both datasets\n",
    "data= pd.concat([repdata, demdata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f901bf8b-c3c5-4ff2-9a76-7314e876d430",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode the target variable as numerical 1 for Republican 0 for Dem\n",
    "data['subreddit']= data['subreddit'].map({'Republican': 1, 'democrats':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4608b547-9e47-45f5-8e21-c6ff857ae595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>title_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>'extremely concerning': elon musk on child por...</td>\n",
       "      <td>BroSteveWinter</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>florida gov. desantis says majority of post-hu...</td>\n",
       "      <td>tbburns2017</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>louden county virginia man arrested on child s...</td>\n",
       "      <td>tbburns2017</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>twitter shares soar on report elon musk agrees...</td>\n",
       "      <td>PinkClouds20</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>hollywood turns on kamala harris, ends vp’s po...</td>\n",
       "      <td>Patriots-United</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit                                              title  \\\n",
       "0          1  'extremely concerning': elon musk on child por...   \n",
       "1          1  florida gov. desantis says majority of post-hu...   \n",
       "2          1  louden county virginia man arrested on child s...   \n",
       "3          1  twitter shares soar on report elon musk agrees...   \n",
       "4          1  hollywood turns on kamala harris, ends vp’s po...   \n",
       "\n",
       "            author  num_comments  title_word_count  \n",
       "0   BroSteveWinter             1                10  \n",
       "1      tbburns2017             1                12  \n",
       "2      tbburns2017             1                13  \n",
       "3     PinkClouds20             1                13  \n",
       "4  Patriots-United             1                12  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9241887f-74f9-4d32-af50-3c1d5a8c6764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7581, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82eff5b2-809b-4386-829c-4fcf3af69f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define X and y\n",
    "X= data['title']\n",
    "y= data['subreddit']\n",
    "\n",
    "#train test split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, random_state= 42, stratify= y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b456a12a-e82e-4f67-9244-a959ea22a9ad",
   "metadata": {},
   "source": [
    "#### Baseline Metrics\n",
    "As seen below the majority class is the Republican Subreddit with a 55% share of the posts within the dataset. This 55% will serve as the baseline accuracy that we should consider when we evaluate our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad49506b-e372-4159-b650-9e1dd13a75ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.550396\n",
       "0    0.449604\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "506f9082-0fda-4462-b752-67a1bbe68fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.550633\n",
       "0    0.449367\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979dcb4c-7c2f-45d0-8139-c14b40ce98df",
   "metadata": {},
   "source": [
    "## Building & Tuning the Models\n",
    "\n",
    "Below I will instantiate, fit, and tune the hyperparameters for each model employing Pipelines and GridSearch to optimize my hyperparamters for each model. I've decided to run 5 models including LogisticRegression, RandomForestClassifier, AdaBoost, Gradient Boost, and a stacked combination of a select group of classification models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658b6547-5081-4551-821d-93606db3e42c",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "This model is similar to linear regression in that we are drawing a line of best fit through our data in order to make a prediction. The difference is that we apply the logit link function to \"bend\" the line of best fit so that it is a curve rather than a straight line. We use this curved line to predict the probability that a data point is in one class versus the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f943326-ff43-452d-a8ed-781b90299592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [2000, 3000, 4000],\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    'cvec__min_df': [1, 2, 4],\n",
    "    'cvec__max_df': [1.0, .5],\n",
    "    'lr__C': [1.0, 0.1],\n",
    "    'lr__penalty': ['l2', 'none']\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe,\n",
    "                 param_grid=pipe_params,\n",
    "                 n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19ca7648-3d59-4a05-a13a-2c50edb4b6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;lr&#x27;, LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;cvec__max_df&#x27;: [1.0, 0.5],\n",
       "                         &#x27;cvec__max_features&#x27;: [2000, 3000, 4000],\n",
       "                         &#x27;cvec__min_df&#x27;: [1, 2, 4],\n",
       "                         &#x27;cvec__stop_words&#x27;: [None, &#x27;english&#x27;],\n",
       "                         &#x27;lr__C&#x27;: [1.0, 0.1], &#x27;lr__penalty&#x27;: [&#x27;l2&#x27;, &#x27;none&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;lr&#x27;, LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;cvec__max_df&#x27;: [1.0, 0.5],\n",
       "                         &#x27;cvec__max_features&#x27;: [2000, 3000, 4000],\n",
       "                         &#x27;cvec__min_df&#x27;: [1, 2, 4],\n",
       "                         &#x27;cvec__stop_words&#x27;: [None, &#x27;english&#x27;],\n",
       "                         &#x27;lr__C&#x27;: [1.0, 0.1], &#x27;lr__penalty&#x27;: [&#x27;l2&#x27;, &#x27;none&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cvec&#x27;, CountVectorizer()), (&#x27;lr&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('lr', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [1.0, 0.5],\n",
       "                         'cvec__max_features': [2000, 3000, 4000],\n",
       "                         'cvec__min_df': [1, 2, 4],\n",
       "                         'cvec__stop_words': [None, 'english'],\n",
       "                         'lr__C': [1.0, 0.1], 'lr__penalty': ['l2', 'none']})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ac02d0b-51e7-4ba5-b05a-c2eaeab17199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7160949868073879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 1.0,\n",
       " 'cvec__max_features': 4000,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__stop_words': 'english',\n",
       " 'lr__C': 1.0,\n",
       " 'lr__penalty': 'l2'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e61e3ee-4d9f-408a-961f-9cff69d242b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving predictions and accuracy scores\n",
    "log_preds = gs.predict(X_test)\n",
    "\n",
    "log_train = gs.score(X_train, y_train)\n",
    "\n",
    "log_test = gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff8ab7c-23f6-414f-af44-955cbed44f77",
   "metadata": {},
   "source": [
    "### Random Forest + Gridsearch\n",
    "\n",
    "RandomForest is essentially a combinination of multiple decision trees using only a random subset of the total features from the dataset. By utilizing random subsets of the features as nodes to split the data into smaller subsets random forest can reduce levels of overfitting typically seen in standard decision tree models. Below I will use a gridsearch to tune the hyperparamters and optimize my model for the best set of max features, tree depth, and number of trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "783757c1-26d7-4f44-a690-2d853728f934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Instantiate the Count Vectorizer\n",
    "cvec= CountVectorizer(stop_words = 'english')\n",
    "\n",
    "X_train_rf = X_train\n",
    "X_test_rf = X_test\n",
    "\n",
    "# #Fit the model\n",
    "cvec.fit(X_train_rf)\n",
    "\n",
    "X_train_rf= cvec.transform(X_train_rf)\n",
    "\n",
    "# #Transform the test set\n",
    "X_test= cvec.transform(X_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1930aae5-b9bb-4f4c-83f8-37deb89321c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7298153034300792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': None, 'max_features': 5, 'n_estimators': 200, 'n_jobs': -1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instantiate the Model and Tune the Parameters\n",
    "rf= RandomForestClassifier(random_state = 42)\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [None, 1, 5],\n",
    "    'max_features' : [1, 3, 5],\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "\n",
    "gs1 = GridSearchCV(rf, param_grid= rf_params, cv = 3, n_jobs = -1)\n",
    "\n",
    "gs1.fit(X_train_rf, y_train)\n",
    "print(gs1.best_score_)\n",
    "gs1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6770f046-dc82-4bfd-843d-4b31fbb4acfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train = gs1.score(X_train_rf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f2f5141-7b6d-4198-b282-cb4760c708f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_test = gs1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92730577-4f97-42bb-b926-4fbf2cd46695",
   "metadata": {},
   "source": [
    "## Boosting Models\n",
    "\n",
    "Boosting is a type of ensemble modeling where we run a model, weight the observations then iterate on the model with the goal of reducing bias and improving accuracy for classification problems. Below I will employ two boosting models Ada and Gradient Boost. These models vary in that Ada weights the observed errors while Gradient Boost fits the next model using the residuals of the prior model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bca8d16d-b843-4ad9-a804-e63b39c2cf4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(random_state=42)),\n",
       "             param_grid={&#x27;base_estimator__max_depth&#x27;: [1, 2],\n",
       "                         &#x27;learning_rate&#x27;: [0.6, 1.0],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 150]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(random_state=42)),\n",
       "             param_grid={&#x27;base_estimator__max_depth&#x27;: [1, 2],\n",
       "                         &#x27;learning_rate&#x27;: [0.6, 1.0],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 150]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(base_estimator=DecisionTreeClassifier(random_state=42))</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(random_state=42)),\n",
       "             param_grid={'base_estimator__max_depth': [1, 2],\n",
       "                         'learning_rate': [0.6, 1.0],\n",
       "                         'n_estimators': [50, 100, 150]})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ada Boost\n",
    "ada= AdaBoostClassifier(base_estimator = DecisionTreeClassifier(random_state = 42))\n",
    "\n",
    "ada_params= {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'base_estimator__max_depth':[1,2],\n",
    "    'learning_rate':[0.6, 1.0]\n",
    "}\n",
    "\n",
    "gs2 = GridSearchCV(ada, param_grid = ada_params, cv = 3)\n",
    "gs2.fit(X_train_rf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f989765-2957-473f-9d5f-dafa593839ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_train = gs2.score(X_train_rf, y_train)\n",
    "\n",
    "ada_test = gs2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d2055bc-19db-4100-bbe9-f5e258493363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6858399296394019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6988396624472574"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Graident Boost\n",
    "gboost= GradientBoostingClassifier(random_state = 42)\n",
    "\n",
    "gboost_params = {\n",
    "    'max_depth': [2, 3, 4],\n",
    "    'n_estimators': [100, 125, 150],\n",
    "    'learning_rate': [0.8, 1.0, 0.1]\n",
    "}\n",
    "\n",
    "gb_gs = GridSearchCV(gboost, param_grid= gboost_params, cv =3)\n",
    "gb_gs.fit(X_train_rf, y_train)\n",
    "print(gb_gs.best_score_)\n",
    "gb_gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d72fafd2-ffd8-4231-a8ea-14568bdb4b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_train = gb_gs.score(X_train_rf, y_train)\n",
    "gb_test = gb_gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e667f0c-3b20-4207-94e3-fce4fb1263bd",
   "metadata": {},
   "source": [
    "### Stacking Models\n",
    "\n",
    "Lastly I will deploy a stacking model, another ensemble model technique. Stacking is a technique wherein predictions are made by multiple models then those predictions are used as features for another model. Here I will use random forest, logistic regression, and ada boost classifier to make my predictions which will then be fit into a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c94a23be-3748-4416-8c88-9d54162fa427",
   "metadata": {},
   "outputs": [],
   "source": [
    "level1_estimators = [\n",
    "    ('random_forest', RandomForestClassifier()),\n",
    "    ('lr', LogisticRegression()),\n",
    "    ('boost', AdaBoostClassifier())\n",
    "]\n",
    "\n",
    "stacked_model = StackingClassifier(estimators=level1_estimators,\n",
    "                                 final_estimator = LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e6b70bf-e081-47e7-9dec-2c35d154a4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;random_forest&#x27;, RandomForestClassifier()),\n",
       "                               (&#x27;lr&#x27;, LogisticRegression()),\n",
       "                               (&#x27;boost&#x27;, AdaBoostClassifier())],\n",
       "                   final_estimator=LogisticRegression())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(estimators=[(&#x27;random_forest&#x27;, RandomForestClassifier()),\n",
       "                               (&#x27;lr&#x27;, LogisticRegression()),\n",
       "                               (&#x27;boost&#x27;, AdaBoostClassifier())],\n",
       "                   final_estimator=LogisticRegression())</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>random_forest</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>boost</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingClassifier(estimators=[('random_forest', RandomForestClassifier()),\n",
       "                               ('lr', LogisticRegression()),\n",
       "                               ('boost', AdaBoostClassifier())],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit\n",
    "stacked_model.fit(X_train_rf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a7bc021-2097-4911-93ea-47893bf9c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train score\n",
    "stack_train= stacked_model.score(X_train_rf, y_train)\n",
    "\n",
    "# Test score\n",
    "stack_test = stacked_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c33532-e93d-4fc5-a9a6-074807705362",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "The main metric I will use to evaluate each model is the accuracy score which represents what percentage of the train and testing set did the model correctly classify. To take things further I will also review the specificity and sensitivity scores. Hypothetically I may care more about correctly identifying my base voter so depending on whether my base in Democrat or Republican I can use sensitivity or specificity to evaluate each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "867f65a9-33e9-48fb-a1e6-29344568f3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_scores</th>\n",
       "      <th>test_scores</th>\n",
       "      <th>diff</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logreg</th>\n",
       "      <td>0.919789</td>\n",
       "      <td>0.716245</td>\n",
       "      <td>0.203544</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.998065</td>\n",
       "      <td>0.747363</td>\n",
       "      <td>0.250702</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>0.777485</td>\n",
       "      <td>0.685127</td>\n",
       "      <td>0.092358</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>0.875462</td>\n",
       "      <td>0.698840</td>\n",
       "      <td>0.176622</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stack</th>\n",
       "      <td>0.992612</td>\n",
       "      <td>0.733122</td>\n",
       "      <td>0.259490</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        train_scores  test_scores      diff  baseline\n",
       "logreg      0.919789     0.716245  0.203544      0.55\n",
       "rf          0.998065     0.747363  0.250702      0.55\n",
       "ada         0.777485     0.685127  0.092358      0.55\n",
       "gb          0.875462     0.698840  0.176622      0.55\n",
       "stack       0.992612     0.733122  0.259490      0.55"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores = [log_train, rf_train, ada_train, gb_train, stack_train]\n",
    "eval_df = pd.DataFrame(train_scores, columns = ['train_scores'])\n",
    "\n",
    "eval_df['test_scores'] = [log_test, rf_test, ada_test, gb_test, stack_test]\n",
    "eval_df.index = ['logreg', 'rf', 'ada', 'gb', 'stack']\n",
    "eval_df['diff'] = eval_df['train_scores'] - eval_df['test_scores']\n",
    "eval_df['baseline'] = .55\n",
    "\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "90983880-a92d-4f75-8229-f1356d4b41b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#False Positive and Negative Scores\n",
    "log_tn, log_fp, log_fn, log_tp = confusion_matrix(y_test, log_preds).ravel()\n",
    "rf_tn, rf_fp, rf_fn, rf_tp = confusion_matrix(y_test, gs1.predict(X_test)).ravel()\n",
    "ada_tn, ada_fp, ada_fn, ada_tp = confusion_matrix(y_test, gs2.predict(X_test)).ravel()\n",
    "gb_tn, gb_fp, gb_fn, gb_tp = confusion_matrix(y_test, gb_gs.predict(X_test)).ravel()\n",
    "st_tn, st_fp, st_fn, st_tp = confusion_matrix(y_test, stacked_model.predict(X_test)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "68301e97-5c28-4194-960c-ffc569456f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Sensitivity Scores\n",
    "log_sens = log_tp / (log_tp + log_fn)\n",
    "rf_sens = rf_tp / (rf_tp + rf_fn)\n",
    "ada_sens = ada_tp / (ada_tp + ada_fn)\n",
    "gb_sens = gb_tp / (gb_tp + gb_fn)\n",
    "st_sens = st_tp / (st_tp + st_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ba3a938f-c3c1-43b2-9364-c8745aa657ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Specificity Scores\n",
    "log_spec = log_tn / (log_tn + log_fp)\n",
    "rf_spec = rf_tn / (rf_tn + rf_fp)\n",
    "ada_spec = ada_tn / (ada_tn + ada_fp)\n",
    "gb_spec = gb_tn / (gb_tn + gb_fp)\n",
    "st_spec = st_tn / (st_tn + st_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f6103ccf-2619-4707-9719-4193b8d6ce48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logreg</th>\n",
       "      <td>0.743295</td>\n",
       "      <td>0.683099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.792146</td>\n",
       "      <td>0.692488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>0.768199</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>0.774904</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stack</th>\n",
       "      <td>0.771073</td>\n",
       "      <td>0.686620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sensitivity  specificty\n",
       "logreg     0.743295    0.683099\n",
       "rf         0.792146    0.692488\n",
       "ada        0.768199    0.583333\n",
       "gb         0.774904    0.605634\n",
       "stack      0.771073    0.686620"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate a Dataframe showing specificity and sensitivity scores\n",
    "sens_scores = [log_sens, rf_sens, ada_sens, gb_sens, st_sens]\n",
    "metrics_df = pd.DataFrame(sens_scores, columns = ['sensitivity'])\n",
    "\n",
    "metrics_df['specificty'] = [log_spec, rf_spec, ada_spec, gb_spec, st_spec]\n",
    "metrics_df.index = ['logreg', 'rf', 'ada', 'gb', 'stack']\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a178d228-b38e-4c33-b4d0-330fb657bb8e",
   "metadata": {},
   "source": [
    "### Results & Conclusions\n",
    "\n",
    "As you can see each model is suffering from overfitting to the training dataset as they are all showing higher accuracy scores in training as compared to test. Ultimately the Random Forest Classifier was the optimal model with the highest testing accuracy of approximately 75% which is 20% above the baseline accuracy from our null model. Given the significant overlap in the words being used by both democrat and republican subreddits, I am satisfied with an accuracy score of 75%. Additionally the Random Forest also had the highest sensitivity and specificity scores so regardless if I am more concerned with prediciting my base as a Democrat or Republican I should choose the Random Forest to minimize false positives and negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5f3ee8-118a-4d1d-ae98-309b0148e4d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
