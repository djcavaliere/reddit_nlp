{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc5f76b2-5029-4f53-ab49-1c639e61b867",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "As a data scientist working on the next presidential campaign I need to get an understanding of what the voting base cares whether they are Republican or Democrat so that we can build a successful and flexible campaign. In this exercise I will collect user posts from Democrat and Republican subreddits and utilize NLP to identify what topics are top of mind and how each voter base is feeling about these topics utlizing Sentiment Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bb79551-88b8-4a44-ac39-f9ed47c42b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26509768-c83d-4e7c-8934-b56a2b075a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r demdata\n",
    "%store -r repdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b81739f-4d17-4167-a1d4-c8b6ddb0a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.concat([repdata, demdata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f901bf8b-c3c5-4ff2-9a76-7314e876d430",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode the target variable as numerical. 1 for Republican 0 for Dem\n",
    "data['subreddit']= data['subreddit'].map({'Republican': 1, 'democrats':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba04089e-a35d-40a5-bfcf-82020227f1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['title'] = data['title'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82eff5b2-809b-4386-829c-4fcf3af69f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define X and y\n",
    "X= data['title']\n",
    "y= data['subreddit']\n",
    "\n",
    "#train test split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, random_state= 42, stratify= y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3074c83b-9712-44fe-a992-64dde14dd02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      " 1    0.500233\n",
      "0    0.499767\n",
      "Name: subreddit, dtype: float64\n",
      "Test:\n",
      " 1    0.5003\n",
      "0    0.4997\n",
      "Name: subreddit, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Check distribution of target variable on train and test sets\n",
    "print(f'Train:\\n',y_train.value_counts(normalize=True))\n",
    "print(f'Test:\\n', y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d513d259-2da5-42f5-84e4-0d1f2a5cb138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit     0\n",
       "title         0\n",
       "selftext     10\n",
       "author        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979dcb4c-7c2f-45d0-8139-c14b40ce98df",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f943326-ff43-452d-a8ed-781b90299592",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [2000, 3000, 4000],\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    'cvec__min_df': [1, 2, 4],\n",
    "    'cvec__max_df': [1.0, .5],\n",
    "    'lr__C': [1.0, 0.1],\n",
    "    'lr__penalty': ['l2', 'none']\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe,\n",
    "                 param_grid=pipe_params,\n",
    "                 n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19ca7648-3d59-4a05-a13a-2c50edb4b6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('lr', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [1.0, 0.5],\n",
       "                         'cvec__max_features': [2000, 3000, 4000],\n",
       "                         'cvec__min_df': [1, 2, 4],\n",
       "                         'cvec__stop_words': [None, 'english'],\n",
       "                         'lr__C': [1.0, 0.1], 'lr__penalty': ['l2', 'none']})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ac02d0b-51e7-4ba5-b05a-c2eaeab17199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6658666297705195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 1.0,\n",
       " 'cvec__max_features': 4000,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__stop_words': 'english',\n",
       " 'lr__C': 0.1,\n",
       " 'lr__penalty': 'l2'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32e5ef98-a228-48ab-856e-97006282a515",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3b912aa-378c-4de3-910e-59ae8d966dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7477152958441732"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9797c30a-7726-4857-bb11-5e1e1380b293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6641985191114669"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff8ab7c-23f6-414f-af44-955cbed44f77",
   "metadata": {},
   "source": [
    "### Random Forest + Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "783757c1-26d7-4f44-a690-2d853728f934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Instantiate the Count Vectorizer\n",
    "cvec= CountVectorizer(stop_words = 'english')\n",
    "\n",
    "X_train_rf = X_train\n",
    "X_test_rf = X_test\n",
    "\n",
    "# #Fit the model\n",
    "cvec.fit(X_train_rf)\n",
    "\n",
    "X_train_rf= cvec.transform(X_train_rf)\n",
    "\n",
    "# #Transform the test set\n",
    "X_test= cvec.transform(X_test_rf)\n",
    "\n",
    "# #Visualize the train data\n",
    "#train_df = pd.DataFrame(X_train.todense(), columns = cvec.get_feature_names_out())\n",
    "\n",
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1930aae5-b9bb-4f4c-83f8-37deb89321c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6631979187512508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': None, 'max_features': 5, 'n_estimators': 150, 'n_jobs': -1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf= RandomForestClassifier()\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [None, 1, 5],\n",
    "    'max_features' : [1, 3, 5],\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(rf, param_grid= rf_params, cv = 3, n_jobs = -1)\n",
    "\n",
    "gs.fit(X_train_rf, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6770f046-dc82-4bfd-843d-4b31fbb4acfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9869254886265092"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_train_rf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f2f5141-7b6d-4198-b282-cb4760c708f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6712027216329798"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92730577-4f97-42bb-b926-4fbf2cd46695",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bca8d16d-b843-4ad9-a804-e63b39c2cf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dylan\\anaconda3.1\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cvec2 = CountVectorizer(stop_words = 'english')\n",
    "\n",
    "vec_data = cvec2.fit_transform(data['title'])\n",
    "\n",
    "#Convert to DataFrame \n",
    "vec_data = pd.DataFrame(vec_data.toarray(), columns= cvec2.get_feature_names())\n",
    "\n",
    "#Concat with original DataFrame\n",
    "vec_data = pd.concat([data, vec_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d2055bc-19db-4100-bbe9-f5e258493363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dylan\\AppData\\Local\\Temp\\ipykernel_5684\\2199519857.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  vec_data[vec_data['subreddit'] == 0].sum().sort_values(ascending= False).head(30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "trump          1132.0\n",
       "biden           850.0\n",
       "democrats       350.0\n",
       "gop             342.0\n",
       "republicans     318.0\n",
       "fbi             317.0\n",
       "new             272.0\n",
       "says            271.0\n",
       "house           236.0\n",
       "president       218.0\n",
       "election        211.0\n",
       "joe             205.0\n",
       "abortion        205.0\n",
       "republican      204.0\n",
       "lago            191.0\n",
       "mar             191.0\n",
       "senate          185.0\n",
       "court           171.0\n",
       "desantis        162.0\n",
       "poll            148.0\n",
       "just            145.0\n",
       "state           143.0\n",
       "white           143.0\n",
       "people          139.0\n",
       "america         135.0\n",
       "raid            133.0\n",
       "video           133.0\n",
       "florida         131.0\n",
       "news            129.0\n",
       "inflation       121.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_data[vec_data['subreddit'] == 0].sum().sort_values(ascending= False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db1cebf8-2fe5-4bc7-b399-ae3d0d6b558c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dylan\\AppData\\Local\\Temp\\ipykernel_5684\\3475685660.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  vec_data[vec_data['subreddit'] == 1].sum().sort_values(ascending= False).head(30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "subreddit               3255.0\n",
       "political                  1.0\n",
       "gov                        1.0\n",
       "politics                   1.0\n",
       "receiving                  1.0\n",
       "democratic                 1.0\n",
       "immigration                1.0\n",
       "approve                    1.0\n",
       "blockloanforgiveness       1.0\n",
       "biden                      1.0\n",
       "loan                       1.0\n",
       "greg                       1.0\n",
       "karma                      1.0\n",
       "kicked                     1.0\n",
       "plan                       1.0\n",
       "joke                       1.0\n",
       "programmed                 1.0\n",
       "new                        1.0\n",
       "humor                      1.0\n",
       "little                     1.0\n",
       "help                       1.0\n",
       "abbott                     1.0\n",
       "piss                       1.0\n",
       "proof                      1.0\n",
       "stop                       1.0\n",
       "birds                      1.0\n",
       "response                   1.0\n",
       "student                    1.0\n",
       "protest                    1.0\n",
       "make                       1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_data[vec_data['subreddit'] == 1].sum().sort_values(ascending= False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c94a23be-3748-4416-8c88-9d54162fa427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>000</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>09</th>\n",
       "      <th>...</th>\n",
       "      <th>влиянии</th>\n",
       "      <th>на</th>\n",
       "      <th>немного</th>\n",
       "      <th>психику</th>\n",
       "      <th>родителей</th>\n",
       "      <th>сдвг</th>\n",
       "      <th>хабр</th>\n",
       "      <th>司馬南版</th>\n",
       "      <th>敦促蔡英文及其軍政首腦投降書</th>\n",
       "      <th>蔡英文</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>report: elite colorado resorts panic as migran...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dow ends nearly 460 points lower as nasdaq plu...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>late gop rep jackie walorski’s brother respond...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>the ‘sticky’ high prices unlikely to come down...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>‘apparent sabotage’: nordic states probe russi...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3430</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3255 rows × 9885 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subreddit                                              title selftext  \\\n",
       "0             1  report: elite colorado resorts panic as migran...            \n",
       "1             1  dow ends nearly 460 points lower as nasdaq plu...            \n",
       "2             1  late gop rep jackie walorski’s brother respond...            \n",
       "3             1  the ‘sticky’ high prices unlikely to come down...            \n",
       "4             1  ‘apparent sabotage’: nordic states probe russi...            \n",
       "...         ...                                                ...      ...   \n",
       "325           1                                                  0      NaN   \n",
       "1183          1                                                  0      NaN   \n",
       "1292          1                                                  0      NaN   \n",
       "2834          1                                                  0      NaN   \n",
       "3430          1                                                  0      NaN   \n",
       "\n",
       "      000   02   03   06   07   08   09  ...  влиянии   на  немного  психику  \\\n",
       "0     NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...      NaN  NaN      NaN      NaN   \n",
       "1     NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...      NaN  NaN      NaN      NaN   \n",
       "2     NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...      NaN  NaN      NaN      NaN   \n",
       "3     NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...      NaN  NaN      NaN      NaN   \n",
       "4     NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...      NaN  NaN      NaN      NaN   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...      ...  ...      ...      ...   \n",
       "325   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0  0.0      0.0      0.0   \n",
       "1183  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0  0.0      0.0      0.0   \n",
       "1292  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0  0.0      0.0      0.0   \n",
       "2834  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0  0.0      0.0      0.0   \n",
       "3430  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0  0.0      0.0      0.0   \n",
       "\n",
       "      родителей  сдвг  хабр  司馬南版  敦促蔡英文及其軍政首腦投降書  蔡英文  \n",
       "0           NaN   NaN   NaN   NaN             NaN  NaN  \n",
       "1           NaN   NaN   NaN   NaN             NaN  NaN  \n",
       "2           NaN   NaN   NaN   NaN             NaN  NaN  \n",
       "3           NaN   NaN   NaN   NaN             NaN  NaN  \n",
       "4           NaN   NaN   NaN   NaN             NaN  NaN  \n",
       "...         ...   ...   ...   ...             ...  ...  \n",
       "325         0.0   0.0   0.0   0.0             0.0  0.0  \n",
       "1183        0.0   0.0   0.0   0.0             0.0  0.0  \n",
       "1292        0.0   0.0   0.0   0.0             0.0  0.0  \n",
       "2834        0.0   0.0   0.0   0.0             0.0  0.0  \n",
       "3430        0.0   0.0   0.0   0.0             0.0  0.0  \n",
       "\n",
       "[3255 rows x 9885 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_data[vec_data['subreddit'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e6b70bf-e081-47e7-9dec-2c35d154a4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dylan\\anaconda3.1\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "tempdf = pd.DataFrame(X_train_rf.toarray(), columns= cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e80b7270-4e64-49ff-a01a-baa01745971e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit    3\n",
       "response     1\n",
       "stop         1\n",
       "biden        1\n",
       "plan         1\n",
       "            ..\n",
       "failure      0\n",
       "fails        0\n",
       "failing      0\n",
       "failed       0\n",
       "蔡英文          0\n",
       "Length: 8596, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempdf[tempdf['subreddit']== 1].sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3323ce9f-4607-49de-8f32-8997c73a8b56",
   "metadata": {},
   "source": [
    "##### Republican Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17d8fbb3-2f4d-461f-a0da-bd961f436315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dylan\\AppData\\Local\\Temp\\ipykernel_5684\\3882148893.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  repdata['title'] = repdata['title'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "rep_vec = CountVectorizer(stop_words = 'english')\n",
    "\n",
    "repdata['title'] = repdata['title'].str.lower()\n",
    "\n",
    "X_rep= repdata['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3bd8b45-b35e-4611-9ca0-7b2023c908af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rep= rep_vec.fit_transform(X_rep)\n",
    "\n",
    "repdf = pd.DataFrame(X_rep.todense(), columns = rep_vec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6103ccf-2619-4707-9719-4193b8d6ce48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trump           504\n",
       "biden           489\n",
       "fbi             247\n",
       "new             145\n",
       "republicans     134\n",
       "says            125\n",
       "joe             111\n",
       "raid            106\n",
       "president       105\n",
       "republican      100\n",
       "gop             100\n",
       "election         99\n",
       "video            98\n",
       "democrats        97\n",
       "desantis         96\n",
       "just             87\n",
       "lago             86\n",
       "mar              86\n",
       "house            85\n",
       "inflation        80\n",
       "people           79\n",
       "hunter           77\n",
       "america          74\n",
       "white            69\n",
       "florida          68\n",
       "poll             67\n",
       "news             66\n",
       "doj              65\n",
       "democrat         65\n",
       "report           64\n",
       "state            64\n",
       "americans        60\n",
       "red              58\n",
       "covid            58\n",
       "like             57\n",
       "2024             57\n",
       "media            53\n",
       "american         53\n",
       "watch            50\n",
       "donald           49\n",
       "senate           48\n",
       "make             47\n",
       "claims           47\n",
       "gov              47\n",
       "court            46\n",
       "conservative     46\n",
       "maga             46\n",
       "amp              45\n",
       "police           45\n",
       "speech           45\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repdf.sum().sort_values(ascending = False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9da561-1277-4ab8-aec7-6def089fe5c1",
   "metadata": {},
   "source": [
    "### Dem Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c9ca2e4-efb3-4bbe-81c4-478a9ab082ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dylan\\AppData\\Local\\Temp\\ipykernel_5684\\3050816361.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  demdata['title'] = demdata['title'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "dem_vec = CountVectorizer(stop_words = 'english')\n",
    "\n",
    "demdata['title'] = demdata['title'].str.lower()\n",
    "\n",
    "X_dem= demdata['title']\n",
    "\n",
    "X_dem= dem_vec.fit_transform(X_dem)\n",
    "\n",
    "demdf = pd.DataFrame(X_dem.todense(), columns = dem_vec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9119222-3e72-4e1b-b463-854df7946186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trump          628\n",
       "biden          362\n",
       "democrats      253\n",
       "gop            242\n",
       "republicans    184\n",
       "abortion       179\n",
       "house          151\n",
       "says           146\n",
       "senate         137\n",
       "new            128\n",
       "court          125\n",
       "president      113\n",
       "election       112\n",
       "lago           105\n",
       "mar            105\n",
       "republican     104\n",
       "joe             94\n",
       "judge           86\n",
       "supreme         84\n",
       "texas           83\n",
       "poll            81\n",
       "state           79\n",
       "vote            76\n",
       "white           74\n",
       "fbi             70\n",
       "donald          67\n",
       "desantis        66\n",
       "manchin         66\n",
       "news            63\n",
       "documents       63\n",
       "florida         63\n",
       "right           63\n",
       "america         61\n",
       "democratic      61\n",
       "special         61\n",
       "people          60\n",
       "rights          59\n",
       "climate         59\n",
       "roe             58\n",
       "just            58\n",
       "party           56\n",
       "race            56\n",
       "act             55\n",
       "voters          55\n",
       "jan             55\n",
       "help            55\n",
       "say             52\n",
       "2022            50\n",
       "maga            50\n",
       "doj             50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demdf.sum().sort_values(ascending = False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223d0709-4f31-4134-ac55-75aabfa8578c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
